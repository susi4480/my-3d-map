# -*- coding: utf-8 -*-
"""
0630no1.py
ã€æ©Ÿèƒ½ã€‘
å·åº•ç‚¹ç¾¤ã‚’2Dã‚°ãƒªãƒƒãƒ‰åŒ– â†’ SORãƒã‚¤ã‚ºé™¤å» â†’ Morphologyè£œé–“
â†’ åŠå¾„1mä»¥å†…ã®è¿‘å‚500ç‚¹ã®å¹³å‡Zã§é«˜ã•ä»˜ä¸
â†’ è£œé–“ç‚¹ã‚’èµ¤è‰²ã«è¨­å®šã—ã€ä»¥ä¸‹2ã¤ã®LASã‚’å‡ºåŠ›
  1. å…ƒç‚¹ç¾¤ï¼‹è£œé–“ç‚¹çµ±åˆLASï¼ˆè£œé–“ç‚¹ã¯èµ¤ï¼‰
  2. è£œé–“ç‚¹ã®ã¿LASï¼ˆèµ¤ï¼‰
"""

import os
import glob
import numpy as np
from pyproj import Transformer, CRS
from skimage.morphology import binary_closing, disk
import laspy
from scipy.spatial import cKDTree
import open3d as o3d  # â˜…SORã«ä½¿ç”¨

# === è¨­å®š ===
input_dir = r"/data/fulldata/floor_sita_xyz/"
output_las_merged = r"/output/0827_suidoubasi_floor_sita_merged_SOR.las"
output_las_interp_only = r"/output/0827_suidoubasi_floor_sita_interp_only_SOR.las"
voxel_size = 0.05
z_upper_limit = 3.0
morph_radius = 100
search_radius = 7.0      # è¿‘å‚æ¢ç´¢åŠå¾„[m]
max_neighbors = 500      # è¿‘å‚æœ€å¤§ç‚¹æ•°
sor_neighbors = 100       # â˜…SORè¿‘å‚ç‚¹æ•°
sor_std_ratio = 0.8      # â˜…SORé™¤å»ã®ã—ãã„å€¤

# === XYZèª­ã¿è¾¼ã¿ï¼ˆNaNé™¤å»ã‚ã‚Šï¼‰===
def load_xyz_files(directory):
    all_points = []
    files = glob.glob(os.path.join(directory, "*.xyz"))
    for f in files:
        try:
            data = np.loadtxt(f, dtype=float)
            if data.ndim == 1 and data.size == 3:
                data = data.reshape(1, 3)
            elif data.ndim != 2 or data.shape[1] != 3:
                print(f"âš  ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {f}")
                continue
            data = data[~np.isnan(data).any(axis=1)]  # NaNé™¤å»
            all_points.append(data)
        except Exception as e:
            print(f"âš  èª­ã¿è¾¼ã¿å¤±æ•—: {f} â†’ {e}")
    if not all_points:
        raise RuntimeError("âŒ æœ‰åŠ¹ãª .xyz ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
    return np.vstack(all_points)

# === [1] ç‚¹ç¾¤èª­ã¿è¾¼ã¿ ===
floor_points = load_xyz_files(input_dir)
print(f"âœ… å…ƒã®ç‚¹æ•°: {len(floor_points):,}")

# === [2] ç·¯åº¦çµŒåº¦ â†’ UTMã«å¤‰æ› ===
transformer = Transformer.from_crs("epsg:4326", "epsg:32654", always_xy=True)
x_utm, y_utm = transformer.transform(floor_points[:, 1], floor_points[:, 0])
points_utm = np.column_stack((x_utm, y_utm, floor_points[:, 2]))

# === [3] Z<3.0 ã®ç‚¹ã ã‘æŠ½å‡º ===
mask = points_utm[:, 2] <= z_upper_limit
filtered_points = points_utm[mask]
print(f"âœ… Zåˆ¶é™å¾Œã®ç‚¹æ•°: {len(filtered_points):,}")

# === [4] SORãƒã‚¤ã‚ºé™¤å» ===
print("ğŸ”¹ SORãƒã‚¤ã‚ºé™¤å»ä¸­...")
pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(filtered_points)
pcd_clean, ind = pcd.remove_statistical_outlier(
    nb_neighbors=sor_neighbors,
    std_ratio=sor_std_ratio
)
clean_points = np.asarray(pcd_clean.points)
print(f"âœ… SORå¾Œã®ç‚¹æ•°: {len(clean_points):,} / {len(filtered_points):,} ({len(filtered_points)-len(clean_points)} ç‚¹é™¤å»)")

# === [5] 2Dã‚°ãƒªãƒƒãƒ‰åŒ– ===
min_x, min_y = clean_points[:, 0].min(), clean_points[:, 1].min()
ix = np.floor((clean_points[:, 0] - min_x) / voxel_size).astype(int)
iy = np.floor((clean_points[:, 1] - min_y) / voxel_size).astype(int)

grid_shape = (ix.max() + 1, iy.max() + 1)
grid = np.zeros(grid_shape, dtype=bool)
grid[ix, iy] = True

# === [6] Morphologyè£œé–“ï¼ˆã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰===
grid_closed = binary_closing(grid, footprint=disk(morph_radius))

# === [7] æ–°ãŸã«è¿½åŠ ã•ã‚ŒãŸç‚¹ã‚’æŠ½å‡º ===
new_mask = (grid_closed & ~grid)
new_ix, new_iy = np.where(new_mask)
new_x = new_ix * voxel_size + min_x
new_y = new_iy * voxel_size + min_y
new_xy = np.column_stack((new_x, new_y))

# === [8] è¿‘å‚500ç‚¹ã®å¹³å‡Zã§é«˜ã•è£œå®Œ ===
tree = cKDTree(clean_points[:, :2])
dists, idxs = tree.query(new_xy, k=max_neighbors, distance_upper_bound=search_radius)

new_z = np.full(len(new_xy), np.nan)
for i in range(len(new_xy)):
    valid = np.isfinite(dists[i]) & (dists[i] < np.inf)
    if not np.any(valid):
        continue
    neighbor_z = clean_points[idxs[i, valid], 2]
    new_z[i] = np.mean(neighbor_z)

valid_points = ~np.isnan(new_z)
new_points = np.column_stack((new_xy[valid_points], new_z[valid_points]))
print(f"âœ… è£œé–“ç‚¹æ•°: {len(new_points):,}")

# === [9] å…ƒç‚¹ç¾¤ã¨è£œé–“ç‚¹ã‚’çµ±åˆ ===
merged_points = np.vstack([clean_points, new_points])
print(f"ğŸ“¦ åˆè¨ˆç‚¹æ•°: {len(merged_points):,}")

# === [10] è‰²è¨­å®š ===
merged_colors = np.zeros((len(merged_points), 3), dtype=np.uint16)
merged_colors[:len(clean_points)] = [65535, 65535, 65535]  # å…ƒç‚¹ç¾¤ = ç™½
merged_colors[len(clean_points):] = [65535, 0, 0]          # è£œé–“ç‚¹ = èµ¤

interp_colors = np.full((len(new_points), 3), [65535, 0, 0], dtype=np.uint16)

# === [11] LASä¿å­˜é–¢æ•° ===
def write_las_with_color(points, colors, out_path):
    header = laspy.LasHeader(point_format=3, version="1.2")
    header.offsets = points.min(axis=0)
    header.scales = np.array([0.001, 0.001, 0.001])
    header.add_crs(CRS.from_epsg(32654))

    las = laspy.LasData(header)
    las.x = points[:, 0]
    las.y = points[:, 1]
    las.z = points[:, 2]
    las.red = colors[:, 0]
    las.green = colors[:, 1]
    las.blue = colors[:, 2]
    las.write(out_path)
    print(f"ğŸ’¾ LASå‡ºåŠ›å®Œäº†: {out_path}")

# === [12] LASå‡ºåŠ› ===
write_las_with_color(merged_points, merged_colors, output_las_merged)
write_las_with_color(new_points, interp_colors, output_las_interp_only)

print("ğŸ‰ ã™ã¹ã¦ã®LASå‡ºåŠ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
