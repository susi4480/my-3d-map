# -*- coding: utf-8 -*-
"""
0827no1.py
ã€æ©Ÿèƒ½ã€‘
å·åº•ç‚¹ç¾¤ã‚’2Dã‚°ãƒªãƒƒãƒ‰åŒ– â†’ RORãƒã‚¤ã‚ºé™¤å» â†’ Morphologyè£œé–“
â†’ åŠå¾„1mä»¥å†…ã®è¿‘å‚500ç‚¹ã®å¹³å‡Zã§é«˜ã•ä»˜ä¸
â†’ å‡ºåŠ›LASã¯1ã¤ã«çµ±åˆ
  - ç™½ : å…ƒç‚¹ç¾¤ï¼ˆRORå¾Œã«æ®‹ã£ãŸç‚¹ï¼‰
  - é’ : RORã§é™¤å»ã•ã‚ŒãŸç‚¹
  - èµ¤ : è£œé–“ç‚¹
"""

import os
import glob
import numpy as np
from pyproj import Transformer, CRS
from skimage.morphology import binary_closing, disk
import laspy
from scipy.spatial import cKDTree
import open3d as o3d  # â˜…RORã«ä½¿ç”¨

# === è¨­å®š ===
input_dir = r"/data/fulldata/floor_ue_xyz/"
output_las_merged = r"/output/0827_suidoubasi_floor_ue_merged_ROR.las"
voxel_size = 0.05
z_upper_limit = 3.0
morph_radius = 100
search_radius = 6.0      # è¿‘å‚æ¢ç´¢åŠå¾„[m]
max_neighbors = 300      # è¿‘å‚æœ€å¤§ç‚¹æ•°

# â˜…RORãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
ror_radius = 1.0        # åŠå¾„[m]
ror_min_points = 500      # ã“ã®æ•°æœªæº€ãªã‚‰ãƒã‚¤ã‚º

# === XYZèª­ã¿è¾¼ã¿ï¼ˆNaNé™¤å»ã‚ã‚Šï¼‰===
def load_xyz_files(directory):
    all_points = []
    files = glob.glob(os.path.join(directory, "*.xyz"))
    for f in files:
        try:
            data = np.loadtxt(f, dtype=float)
            if data.ndim == 1 and data.size == 3:
                data = data.reshape(1, 3)
            elif data.ndim != 2 or data.shape[1] != 3:
                print(f"âš  ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {f}")
                continue
            data = data[~np.isnan(data).any(axis=1)]  # NaNé™¤å»
            all_points.append(data)
        except Exception as e:
            print(f"âš  èª­ã¿è¾¼ã¿å¤±æ•—: {f} â†’ {e}")
    if not all_points:
        raise RuntimeError("âŒ æœ‰åŠ¹ãª .xyz ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
    return np.vstack(all_points)

# === [1] ç‚¹ç¾¤èª­ã¿è¾¼ã¿ ===
floor_points = load_xyz_files(input_dir)
print(f"âœ… å…ƒã®ç‚¹æ•°: {len(floor_points):,}")

# === [2] ç·¯åº¦çµŒåº¦ â†’ UTMã«å¤‰æ› ===
transformer = Transformer.from_crs("epsg:4326", "epsg:32654", always_xy=True)
x_utm, y_utm = transformer.transform(floor_points[:, 1], floor_points[:, 0])
points_utm = np.column_stack((x_utm, y_utm, floor_points[:, 2]))

# === [3] Z<3.0 ã®ç‚¹ã ã‘æŠ½å‡º ===
mask = points_utm[:, 2] <= z_upper_limit
filtered_points = points_utm[mask]
print(f"âœ… Zåˆ¶é™å¾Œã®ç‚¹æ•°: {len(filtered_points):,}")

# === [4] RORãƒã‚¤ã‚ºé™¤å» ===
print("ğŸ”¹ RORãƒã‚¤ã‚ºé™¤å»ä¸­...")
pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(filtered_points)
pcd_clean, ind = pcd.remove_radius_outlier(nb_points=ror_min_points, radius=ror_radius)

clean_points = np.asarray(pcd_clean.points)         # æ®‹ã£ãŸç‚¹
removed_points = filtered_points[~np.asarray(ind)]  # é™¤å»ã•ã‚ŒãŸç‚¹
print(f"âœ… RORå¾Œã®ç‚¹æ•°: {len(clean_points):,} / {len(filtered_points):,} "
      f"({len(removed_points)} ç‚¹é™¤å»)")

# === [5] 2Dã‚°ãƒªãƒƒãƒ‰åŒ– ===
min_x, min_y = clean_points[:, 0].min(), clean_points[:, 1].min()
ix = np.floor((clean_points[:, 0] - min_x) / voxel_size).astype(int)
iy = np.floor((clean_points[:, 1] - min_y) / voxel_size).astype(int)

grid_shape = (ix.max() + 1, iy.max() + 1)
grid = np.zeros(grid_shape, dtype=bool)
grid[ix, iy] = True

# === [6] Morphologyè£œé–“ï¼ˆã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰===
grid_closed = binary_closing(grid, footprint=disk(morph_radius))

# === [7] æ–°ãŸã«è¿½åŠ ã•ã‚ŒãŸç‚¹ã‚’æŠ½å‡º ===
new_mask = (grid_closed & ~grid)
new_ix, new_iy = np.where(new_mask)
new_x = new_ix * voxel_size + min_x
new_y = new_iy * voxel_size + min_y
new_xy = np.column_stack((new_x, new_y))

# === [8] è¿‘å‚500ç‚¹ã®å¹³å‡Zã§é«˜ã•è£œå®Œ ===
tree = cKDTree(clean_points[:, :2])
dists, idxs = tree.query(new_xy, k=max_neighbors, distance_upper_bound=search_radius)

new_z = np.full(len(new_xy), np.nan)
for i in range(len(new_xy)):
    valid = np.isfinite(dists[i]) & (dists[i] < np.inf)
    if not np.any(valid):
        continue
    neighbor_z = clean_points[idxs[i, valid], 2]
    new_z[i] = np.mean(neighbor_z)

valid_points = ~np.isnan(new_z)
new_points = np.column_stack((new_xy[valid_points], new_z[valid_points]))
print(f"âœ… è£œé–“ç‚¹æ•°: {len(new_points):,}")

# === [9] å…ƒç‚¹ç¾¤ãƒ»é™¤å»ç‚¹ãƒ»è£œé–“ç‚¹ã‚’çµ±åˆ ===
all_points = np.vstack([clean_points, removed_points, new_points])
print(f"ğŸ“¦ åˆè¨ˆç‚¹æ•°: {len(all_points):,}")

# === [10] è‰²è¨­å®š ===
colors = np.zeros((len(all_points), 3), dtype=np.uint16)
colors[:len(clean_points)] = [65535, 65535, 65535]   # ç™½ï¼ˆæ®‹ã—ãŸç‚¹ï¼‰
colors[len(clean_points):len(clean_points)+len(removed_points)] = [0, 0, 65535]  # é’ï¼ˆé™¤å»ç‚¹ï¼‰
colors[len(clean_points)+len(removed_points):] = [65535, 0, 0]  # èµ¤ï¼ˆè£œé–“ç‚¹ï¼‰

# === [11] LASä¿å­˜é–¢æ•° ===
def write_las_with_color(points, colors, out_path):
    header = laspy.LasHeader(point_format=3, version="1.2")
    header.offsets = points.min(axis=0)
    header.scales = np.array([0.001, 0.001, 0.001])
    header.add_crs(CRS.from_epsg(32654))

    las = laspy.LasData(header)
    las.x = points[:, 0]
    las.y = points[:, 1]
    las.z = points[:, 2]
    las.red = colors[:, 0]
    las.green = colors[:, 1]
    las.blue = colors[:, 2]
    las.write(out_path)
    print(f"ğŸ’¾ LASå‡ºåŠ›å®Œäº†: {out_path}")

# === [12] LASå‡ºåŠ› ===
write_las_with_color(all_points, colors, output_las_merged)

print("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ã¨LASå‡ºåŠ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
