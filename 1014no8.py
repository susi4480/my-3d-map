# -*- coding: utf-8 -*-
"""
IBGAL v2 å¯è¦–åŒ–å¼·åŒ–ç‰ˆï¼ˆé«˜ç²¾ç´°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + ä¸¡ç”»åƒæ¯”è¼ƒ + é‡ã­åˆã‚ã›ï¼‰
--------------------------------------------------------------------
- å˜ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¹ã‚­ãƒ£ãƒ³ç‚¹ç¾¤ã‚’ä½¿ç”¨ã—ã¦åœ°å›³ä¸Šã®ä½ç½®(Yaw+XY)ã‚’æ¨å®šã€‚
- åœ°å›³PLYã‚’LiDARè¦–ç‚¹ã‹ã‚‰ãƒ‘ãƒãƒ©ãƒç”»åƒåŒ–ã—ã¦NCCã§ç›¸é–¢æœ€å¤§åŒ–ã€‚
- æ¨å®šçµæœã‚’åœ°å›³ä¸Šã«çŸ¢å°ã§æç”»ã€‚
- ã‚¹ã‚­ãƒ£ãƒ³ç”»åƒã¨åœ°å›³ç”»åƒã‚’å·¦å³ä¸¦åˆ—è¡¨ç¤ºï¼†åŠé€æ˜é‡ã­åˆã‚ã›ç”»åƒã§ä¿å­˜ã€‚
"""

import os
import math
import numpy as np
import open3d as o3d
import cv2
import matplotlib.pyplot as plt
from typing import Tuple
from ouster.sdk.open_source import open_source
from ouster.sdk.core import XYZLut, ChanField, SensorInfo

# ========= ãƒ‘ã‚¹è¨­å®š =========
PCAP_PATH = "/workspace/data/realdata/2022-07-06-18-33-15_OS-2-128-992048000507-1024x10-001.pcap"
JSON_PATH = "/workspace/data/realdata/2022-07-06-18-33-15_OS-2-128-992048000507-1024x10.json"
MAP_PATH  = "/workspace/output/1013_lidar_map.ply"
OUTPUT_DIR = "/workspace/output/ibgal_xyyaw_compare"
FRAME_INDEX = 2000

# ========= ç”»åƒåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ¨å¥¨è¨­å®šï¼‰=========
YAW_RES_DEG   = 0.25     # ã‚ˆã‚Šé«˜ç²¾ç´°ï¼ˆ0.25Â°ï¼‰
PITCH_RES_DEG = 0.5      # ã‚ˆã‚Šé«˜ç²¾ç´°ï¼ˆ0.5Â°ï¼‰
Z_RANGE       = None     # é«˜ã•åˆ¶é™ãªã—

# ========= æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ =========
SEARCH_XY_RADIUS = 20.0
SEARCH_XY_STEP   = 5.0
YAW_STEP_DEG     = 5
REFINE_YAW_LOCAL = True

# ========= åœ°å›³ã®è»½é‡åŒ–è¨­å®š =========
MAP_RANDOM_DOWNSAMPLE = 1.0   # ç„¡åŠ¹ï¼ˆå…¨ç‚¹ä½¿ç”¨ï¼‰

# ------------------------------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ------------------------------------------------------------
def ensure_dir(p):
    os.makedirs(p, exist_ok=True)

def deg2rad(d): return d * math.pi / 180.0

def to_polar_image(points: np.ndarray, yaw_res_deg: float, pitch_res_deg: float) -> np.ndarray:
    """ç‚¹ç¾¤ã‚’ãƒ‘ãƒãƒ©ãƒæ·±åº¦ç”»åƒã«å¤‰æ›ï¼ˆ16bit, mmå˜ä½ï¼‰ã€‚"""
    if points.size == 0:
        return np.zeros((int(180/pitch_res_deg), int(360/yaw_res_deg)), np.uint16)
    x, y, z = points[:,0], points[:,1], points[:,2]
    r = np.sqrt(x**2 + y**2 + z**2)
    yaw   = np.arctan2(y, x)
    pitch = np.arctan2(z, np.sqrt(x**2 + y**2))
    yaw_bins   = int(round(360.0 / yaw_res_deg))
    pitch_bins = int(round(180.0 / pitch_res_deg))
    img = np.zeros((pitch_bins, yaw_bins), dtype=np.uint16)
    yi = ((yaw + np.pi) / deg2rad(yaw_res_deg)).astype(np.int32)
    pi = ((pitch + np.pi/2) / deg2rad(pitch_res_deg)).astype(np.int32)
    valid = (yi >= 0) & (yi < yaw_bins) & (pi >= 0) & (pi < pitch_bins)
    yi, pi, rr = yi[valid], pi[valid], r[valid]
    rr_mm = (rr * 1000.0).astype(np.uint16)
    lin = pi * yaw_bins + yi
    maxval = np.iinfo(np.uint16).max
    buf = np.full(img.size, maxval, dtype=np.uint32)
    np.minimum.at(buf, lin, rr_mm.astype(np.uint32))
    img = buf.reshape(pitch_bins, yaw_bins).astype(np.uint16)
    img[img == maxval] = 0
    return img

def ncc_on_valid(a: np.ndarray, b: np.ndarray) -> float:
    m = (a > 0) & (b > 0)
    n = int(m.sum())
    if n < 500: return -1e9
    av = a[m].astype(np.float32); bv = b[m].astype(np.float32)
    av -= av.mean(); bv -= bv.mean()
    denom = np.sqrt((av*av).sum() * (bv*bv).sum()) + 1e-6
    return float((av*bv).sum() / denom)

def roll_yaw(img: np.ndarray, yaw_deg: float, yaw_res_deg: float) -> np.ndarray:
    shift_cols = int(round(yaw_deg / yaw_res_deg))
    return np.roll(img, shift_cols, axis=1)

def pc_to_image_for_viewpoint(map_pts: np.ndarray, viewpoint_xy: Tuple[float,float], z_view: float=0.0) -> np.ndarray:
    vx, vy = viewpoint_xy
    pts = map_pts - np.array([vx, vy, z_view])
    return to_polar_image(pts, YAW_RES_DEG, PITCH_RES_DEG)

def extract_frame_points_from_pcap(pcap_path: str, json_path: str, frame_index: int) -> np.ndarray:
    with open(json_path, "r") as f:
        sensor_info = SensorInfo(f.read())
    xyzlut = XYZLut(sensor_info, use_extrinsics=False)
    source = open_source(pcap_path)
    for i, scans in enumerate(source):
        scan = scans if not isinstance(scans, list) else scans[0]
        if i == frame_index:
            xyz = xyzlut(scan)
            rng = scan.field(ChanField.RANGE)
            valid = (rng > 0)
            pts = xyz.reshape(-1, 3)[valid.reshape(-1)]
            return pts
    raise ValueError(f"æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ  {frame_index} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³
# ------------------------------------------------------------
def main():
    ensure_dir(OUTPUT_DIR)

    print("ğŸ—º åœ°å›³èª­ã¿è¾¼ã¿ä¸­...")
    map_pcd = o3d.io.read_point_cloud(MAP_PATH)
    if MAP_RANDOM_DOWNSAMPLE < 1.0:
        map_pcd = map_pcd.random_down_sample(MAP_RANDOM_DOWNSAMPLE)
    map_pts = np.asarray(map_pcd.points)
    print(f"âœ… åœ°å›³ç‚¹æ•°: {len(map_pts):,}")

    print("ğŸ“¡ ã‚¹ã‚­ãƒ£ãƒ³æŠ½å‡ºä¸­...")
    scan_pts = extract_frame_points_from_pcap(PCAP_PATH, JSON_PATH, FRAME_INDEX)
    print(f"âœ… ã‚¹ã‚­ãƒ£ãƒ³ç‚¹æ•°: {len(scan_pts):,}")

    print("ğŸ–¼ ã‚¹ã‚­ãƒ£ãƒ³ç”»åƒåŒ–...")
    scan_img = to_polar_image(scan_pts, YAW_RES_DEG, PITCH_RES_DEG)
    cv2.imwrite(os.path.join(OUTPUT_DIR, "query_depth.png"),
                cv2.normalize(scan_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8))

    cx, cy, _ = map_pts.mean(axis=0)
    xs = np.arange(cx - SEARCH_XY_RADIUS, cx + SEARCH_XY_RADIUS + 1e-6, SEARCH_XY_STEP)
    ys = np.arange(cy - SEARCH_XY_RADIUS, cy + SEARCH_XY_RADIUS + 1e-6, SEARCH_XY_STEP)
    yaw_candidates = list(range(-180, 181, YAW_STEP_DEG))

    rolled_cache = {yd: roll_yaw(scan_img, yd, YAW_RES_DEG) for yd in yaw_candidates}
    best = dict(score=-1e9, x=None, y=None, yaw=None)

    print("ğŸ” æ¢ç´¢é–‹å§‹ (XYÃ—Yaw)...")
    for y0 in ys:
        for x0 in xs:
            ref_img = pc_to_image_for_viewpoint(map_pts, (x0, y0))
            for yd in yaw_candidates:
                s = ncc_on_valid(ref_img, rolled_cache[yd])
                if s > best["score"]:
                    best.update(score=s, x=x0, y=y0, yaw=yd)
    print(f"âœ… æœ€è‰¯: score={best['score']:.3f}, x={best['x']:.2f}, y={best['y']:.2f}, yaw={best['yaw']:.1f}")

    # ---- å¯è¦–åŒ– ----
    print("ğŸ–¼ å¯è¦–åŒ–å‡ºåŠ›ä¸­...")

    # (1) åœ°å›³ä¸Šã§ä½ç½®ã¨å‘ãã‚’æç”»
    plt.figure(figsize=(8,8))
    plt.scatter(map_pts[:,0], map_pts[:,1], s=0.2, c='gray', alpha=0.5, label="Map")
    plt.arrow(best["x"], best["y"], 
              5*math.cos(deg2rad(best["yaw"])), 5*math.sin(deg2rad(best["yaw"])),
              color='red', head_width=1.0, length_includes_head=True, label="Estimated Pose")
    plt.title("Estimated Position on Map (Red Arrow = LiDAR view)")
    plt.xlabel("X [m]"); plt.ylabel("Y [m]")
    plt.axis("equal"); plt.legend()
    plt.savefig(os.path.join(OUTPUT_DIR, "estimated_pose_on_map.png"), dpi=300)
    plt.close()

    # (2) åœ°å›³ vs ã‚¹ã‚­ãƒ£ãƒ³ä¿¯ç°é‡ã­åˆã‚ã›
    yaw = deg2rad(best["yaw"])
    Rz = np.array([[math.cos(yaw), -math.sin(yaw), 0],
                   [math.sin(yaw),  math.cos(yaw), 0],
                   [0,0,1]])
    scan_transformed = (scan_pts @ Rz.T) + np.array([best["x"], best["y"], 0])
    plt.figure(figsize=(8,8))
    plt.scatter(map_pts[:,0], map_pts[:,1], s=0.2, c='gray', alpha=0.5, label="Map")
    plt.scatter(scan_transformed[:,0], scan_transformed[:,1], s=0.5, c='red', alpha=0.6, label="Scan")
    plt.axis("equal"); plt.legend()
    plt.title("Map vs Scan Alignment (Top-Down)")
    plt.xlabel("X [m]"); plt.ylabel("Y [m]")
    plt.savefig(os.path.join(OUTPUT_DIR, "alignment_topdown.png"), dpi=300)
    plt.close()

    # (3) æ·±åº¦ç”»åƒã®æ¯”è¼ƒï¼ˆå·¦å³ä¸¦åˆ— & åŠé€æ˜é‡ã­ï¼‰
    ref_best = pc_to_image_for_viewpoint(map_pts, (best["x"], best["y"]))
    qry_best = roll_yaw(scan_img, best["yaw"], YAW_RES_DEG)

    ref_norm = cv2.normalize(ref_best, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    qry_norm = cv2.normalize(qry_best, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    cv2.imwrite(os.path.join(OUTPUT_DIR, "reference_depth_best.png"), ref_norm)
    cv2.imwrite(os.path.join(OUTPUT_DIR, "query_depth_rotated.png"), qry_norm)

    # å·¦å³ä¸¦åˆ—æ¯”è¼ƒç”»åƒ
    combined = np.hstack([ref_norm, qry_norm])
    cv2.imwrite(os.path.join(OUTPUT_DIR, "compare_side_by_side.png"), combined)

    # åŠé€æ˜é‡ã­åˆã‚ã›ç”»åƒï¼ˆç·‘=åœ°å›³, èµ¤=ã‚¹ã‚­ãƒ£ãƒ³ï¼‰
    ref_col = cv2.cvtColor(ref_norm, cv2.COLOR_GRAY2BGR)
    qry_col = cv2.cvtColor(qry_norm, cv2.COLOR_GRAY2BGR)
    overlap = cv2.addWeighted(ref_col, 0.5, qry_col, 0.5, 0)
    cv2.imwrite(os.path.join(OUTPUT_DIR, "compare_overlay.png"), overlap)

    print("ğŸ“¸ ç”»åƒå‡ºåŠ›å®Œäº†:")
    print("   - compare_side_by_side.png : å·¦=åœ°å›³ / å³=ã‚¹ã‚­ãƒ£ãƒ³")
    print("   - compare_overlay.png       : åŠé€æ˜é‡ã­åˆã‚ã›")
    print(f"ğŸ§­ æ¨å®šä½ç½®: x={best['x']:.2f}, y={best['y']:.2f}, yaw={best['yaw']:.1f}Â°, score={best['score']:.3f}")

if __name__ == "__main__":
    main()
