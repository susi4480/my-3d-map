# -*- coding: utf-8 -*-
"""
IBGAL v2ï¼ˆScan-to-Map, z=0å›ºå®š, åœ°å›³Zåè»¢ç¶­æŒ, FOVåˆ¶é™, Edge-NCCï¼‰
-----------------------------------------------------------------------
å…¥åŠ›:
  - MAP_PATH  : æ—¢å­˜åœ°å›³ .ply
  - PCAP/JSON : Ouster OS-2 ã®éŒ²ç”»ï¼ˆ1ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼‰

æ‰‹é †:
  1) åœ°å›³PLYèª­ã¿è¾¼ã¿ â†’ Zè»¸åè»¢ï¼ˆmap_pts[:,2]*=-1ï¼‰
  2) PCAP/JSONã‹ã‚‰æŒ‡å®šFRAME_INDEXã®ã‚¹ã‚­ãƒ£ãƒ³ç‚¹ç¾¤æŠ½å‡ºï¼ˆrange>0ï¼‰
  3) ç‚¹ç¾¤ã‚’ãƒ‘ãƒãƒ©ãƒåŒ–ï¼ˆYawÃ—Pitchï¼‰ã€‚Pitchã¯å®Ÿæ©ŸFOVï¼ˆÂ±22.5Â°ï¼‰ã«åˆ¶é™
     - æ·±åº¦ã¯ cmé‡å­åŒ–ï¼ˆmÃ—100ï¼‰ã§ uint16 ã«å®‰å…¨ã‚¯ãƒªãƒƒãƒ—
  4) ç²—æ¢ç´¢â†’ç´°æ¢ç´¢ï¼ˆXYÃ—Yawï¼‰ã€‚å„å€™è£œã§:
     - åœ°å›³å´ã‚’ä»®æƒ³è¦–ç‚¹ (x,y,z=0) ã‹ã‚‰ãƒ¬ãƒ³ãƒ€
     - ã‚¹ã‚­ãƒ£ãƒ³å´ã¯yawåˆ†ã ã‘åˆ—ã‚·ãƒ•ãƒˆ
     - Edge-NCCï¼ˆCannyã‚¨ãƒƒã‚¸å¾Œã®NCC, å…±é€šç”»ç´ é–¾å€¤ã‚ã‚Šï¼‰ã§ã‚¹ã‚³ã‚¢è©•ä¾¡
  5) ãƒ™ã‚¹ãƒˆ (x,y,yaw) ã‚’å¯è¦–åŒ–

å‡ºåŠ›ï¼ˆã“ã®4æšã®ã¿ï¼‰:
  - compare_side_by_side.png
  - compare_overlay_color.png
  - estimated_pose_on_map.png
  - alignment_topdown.png
"""

import os
import math
import numpy as np
import open3d as o3d
import cv2
import matplotlib.pyplot as plt
from typing import Tuple, Optional
from ouster.sdk.open_source import open_source
from ouster.sdk.core import XYZLut, ChanField, SensorInfo

# ========= ãƒ‘ã‚¹ =========
PCAP_PATH  = "/workspace/data/realdata/2022-07-06-18-33-15_OS-2-128-992048000507-1024x10-001.pcap"
JSON_PATH  = "/workspace/data/realdata/2022-07-06-18-33-15_OS-2-128-992048000507-1024x10.json"
MAP_PATH   = "/workspace/data/1013_lidar_map.ply"
OUTPUT_DIR = "/workspace/output/ibgal_xyyaw_compare"
FRAME_INDEX = 5000

# ========= ãƒ‘ãƒãƒ©ãƒè¨­å®š =========
YAW_RES_DEG    = 0.25         # åˆ—è§£åƒåº¦ï¼ˆå°ã•ã„ã»ã©é«˜è§£åƒåº¦ï¼‰
PITCH_RES_DEG  = 0.5          # è¡Œè§£åƒåº¦
PITCH_MIN_DEG  = -22.5        # å®Ÿæ©ŸFOVï¼ˆOS-2ç›®å®‰ï¼‰
PITCH_MAX_DEG  =  22.5
DEPTH_SCALE    = 100.0        # mâ†’cm é‡å­åŒ– (Ã—100)
MAX_U16        = np.iinfo(np.uint16).max

# ========= æ¢ç´¢è¨­å®šï¼ˆç²—â†’ç´°ï¼‰ =========
# è‡ªå‹•ä¸­å¿ƒ: åœ°å›³ã®æœ€å¯†ã‚»ãƒ«ä¸­å¿ƒã‚’ä½¿ã†ï¼ˆä¸‹ã®é–¢æ•°ã§æ¨å®šï¼‰
SEARCH_XY_RADIUS_COARSE = 40.0
SEARCH_XY_STEP_COARSE   = 5.0
YAW_STEP_DEG_COARSE     = 5

SEARCH_XY_RADIUS_FINE   = 10.0
SEARCH_XY_STEP_FINE     = 1.0
YAW_STEP_DEG_FINE       = 1

# ========= ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° =========
NCC_MIN_COMMON_PIX      = 3000   # å…±é€šæœ‰åŠ¹ç”»ç´ ã—ãã„
FAIL_SCORE_THRESHOLD    = 0.25   # ã“ã‚Œæœªæº€ã¯å¤±æ•—æ‰±ã„

# ========= ãã®ä»– =========
MAP_RANDOM_DOWNSAMPLE   = 1.0    # 1.0ã§ç„¡åŠ¹ï¼ˆå¿…è¦ãªã‚‰ 0.5 ç­‰ï¼‰
AUTO_CENTER_BY_DENSITY  = True
COARSE_BIN_M            = 10.0   # æœ€å¯†ã‚»ãƒ«æ¨å®šã®ç²—ãƒ“ãƒ³

# ------------------------------------------------------------
def ensure_dir(p): os.makedirs(p, exist_ok=True)
def deg2rad(d):   return d * math.pi / 180.0

def to_polar_image(points: np.ndarray,
                   yaw_res_deg: float,
                   pitch_res_deg: float,
                   pitch_min_deg: float,
                   pitch_max_deg: float,
                   depth_scale: float) -> np.ndarray:
    """ç‚¹ç¾¤â†’ãƒ‘ãƒãƒ©ãƒæ·±åº¦ç”»åƒ (uint16, å˜ä½=1/depth_scale m, 0=æœªè¦³æ¸¬)ã€‚"""
    yaw_bins   = int(round(360.0 / yaw_res_deg))
    pitch_bins = int(round((pitch_max_deg - pitch_min_deg) / pitch_res_deg))
    if points.size == 0:
        return np.zeros((pitch_bins, yaw_bins), np.uint16)

    x, y, z = points[:, 0], points[:, 1], points[:, 2]
    r = np.sqrt(x**2 + y**2 + z**2)
    yaw   = np.arctan2(y, x)                              # [-pi, pi)
    pitch = np.arctan2(z, np.sqrt(x**2 + y**2))           # [-pi/2, pi/2]

    pmin = deg2rad(pitch_min_deg)
    pmax = deg2rad(pitch_max_deg)
    valid_pitch = (pitch >= pmin) & (pitch <= pmax)

    yi = ((yaw + np.pi) / deg2rad(yaw_res_deg)).astype(np.int32)
    pi = ((pitch - pmin) / deg2rad(pitch_res_deg)).astype(np.int32)
    valid = valid_pitch & (yi >= 0) & (yi < yaw_bins) & (pi >= 0) & (pi < pitch_bins)
    if not np.any(valid):
        return np.zeros((pitch_bins, yaw_bins), np.uint16)

    yi, pi, rr = yi[valid], pi[valid], r[valid]

    rr_q = (rr * depth_scale)
    rr_q = np.minimum(rr_q, float(MAX_U16)).astype(np.uint16)

    img = np.zeros((pitch_bins, yaw_bins), dtype=np.uint16)
    lin = pi * yaw_bins + yi
    buf = np.full(img.size, MAX_U16, dtype=np.uint32)
    np.minimum.at(buf, lin, rr_q.astype(np.uint32))
    img = buf.reshape(pitch_bins, yaw_bins).astype(np.uint16)
    img[img == MAX_U16] = 0
    return img

def to_edges(img_u16: np.ndarray) -> np.ndarray:
    """Cannyã‚¨ãƒƒã‚¸ï¼ˆ0/255ï¼‰ã€‚æ·±åº¦ç”»åƒã‹ã‚‰å½¢çŠ¶å¢ƒç•Œã ã‘ã‚’æŠ½å‡ºã—ã¦NCCã‚’å®‰å®šåŒ–ã€‚"""
    if img_u16.size == 0:
        return img_u16
    g = cv2.GaussianBlur(img_u16, (5, 5), 0)
    # Cannyã¯8bitæƒ³å®šã€‚æ­£è¦åŒ–ã—ã¦ä½¿ã†
    g8 = cv2.normalize(g, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    e = cv2.Canny(g8, 30, 150)
    return e

def ncc_on_valid(a: np.ndarray, b: np.ndarray, min_common: int) -> float:
    """æœªè¦³æ¸¬(0)ã‚’é™¤å¤–ã—ã€å…±é€šç”»ç´ ã®ã¿ã§NCCã€‚é–¾å€¤æœªæº€ãªã‚‰æ¥µå°å€¤ã€‚"""
    m = (a > 0) & (b > 0)
    n = int(m.sum())
    if n < min_common:
        return -1e9
    av = a[m].astype(np.float32); bv = b[m].astype(np.float32)
    av -= av.mean(); bv -= bv.mean()
    denom = np.sqrt((av * av).sum() * (bv * bv).sum()) + 1e-6
    return float((av * bv).sum() / denom)

def roll_yaw(img: np.ndarray, yaw_deg: float, yaw_res_deg: float) -> np.ndarray:
    """Yawå›è»¢ã¯åˆ—ã‚·ãƒ•ãƒˆã«ç­‰ä¾¡ã€‚"""
    shift_cols = int(round(yaw_deg / yaw_res_deg))
    return np.roll(img, shift_cols, axis=1)

def pc_to_image_for_viewpoint(map_pts: np.ndarray,
                              viewpoint_xy: Tuple[float, float],
                              z_view: float = 0.0) -> np.ndarray:
    """è¦–ç‚¹ (x,y,z=z_view) ã‹ã‚‰è¦‹ãŸåœ°å›³ã®ãƒ‘ãƒãƒ©ãƒæ·±åº¦ç”»åƒã€‚"""
    vx, vy = viewpoint_xy
    pts = map_pts - np.array([vx, vy, z_view], dtype=np.float64)
    return to_polar_image(pts, YAW_RES_DEG, PITCH_RES_DEG,
                          PITCH_MIN_DEG, PITCH_MAX_DEG,
                          DEPTH_SCALE)

def extract_frame_points_from_pcap(pcap_path: str, json_path: str, frame_index: int) -> np.ndarray:
    """Ouster PCAP/JSONã‹ã‚‰æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ ã®ç‚¹ç¾¤ã‚’æŠ½å‡ºï¼ˆrange>0ï¼‰ã€‚"""
    with open(json_path, "r") as f:
        sensor_info = SensorInfo(f.read())
    xyzlut = XYZLut(sensor_info, use_extrinsics=False)
    source = open_source(pcap_path)

    for i, scan in enumerate(source):
        if i == frame_index:
            xyz = xyzlut(scan)                             # (H, W, 3)
            rng = scan.field(ChanField.RANGE)              # (H, W)
            valid = (rng > 0)
            pts = xyz.reshape(-1, 3)[valid.reshape(-1)]
            return pts
    raise ValueError(f"æŒ‡å®šãƒ•ãƒ¬ãƒ¼ãƒ  {frame_index} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def auto_center_by_density(map_pts: np.ndarray, bin_m: float) -> Tuple[float, float]:
    """åœ°å›³XYã‚’ç²—ãƒ’ã‚¹ãƒˆã—ã¦æœ€å¯†ã‚»ãƒ«ä¸­å¿ƒã‚’è¿”ã™ã€‚æ¢ç´¢èµ·ç‚¹ã®å®‰å®šåŒ–ã€‚"""
    x_min, x_max = map_pts[:, 0].min(), map_pts[:, 0].max()
    y_min, y_max = map_pts[:, 1].min(), map_pts[:, 1].max()
    nx = max(1, int(np.ceil((x_max - x_min) / bin_m)))
    ny = max(1, int(np.ceil((y_max - y_min) / bin_m)))
    H, xedges, yedges = np.histogram2d(map_pts[:, 0], map_pts[:, 1],
                                       bins=[nx, ny],
                                       range=[[x_min, x_max], [y_min, y_max]])
    iy, ix = np.unravel_index(np.argmax(H), H.shape)
    cx = 0.5 * (xedges[iy] + xedges[iy + 1])
    cy = 0.5 * (yedges[ix] + yedges[ix + 1])
    return float(cx), float(cy)

def search_xy_yaw(map_pts, scan_edge, cx, cy,
                  xy_radius, xy_step, yaw_step_deg):
    """XYÃ—Yaw ã®æ¢ç´¢ï¼ˆEdge-NCCï¼‰ã€‚scan_edge ã¯ã™ã§ã«ã‚¨ãƒƒã‚¸ç”»åƒã€‚"""
    xs = np.arange(cx - xy_radius, cx + xy_radius + 1e-9, xy_step)
    ys = np.arange(cy - xy_radius, cy + xy_radius + 1e-9, xy_step)
    yaw_candidates = list(range(-180, 181, yaw_step_deg))

    # ã‚¹ã‚­ãƒ£ãƒ³å´ã®å›è»¢å€™è£œã‚¨ãƒƒã‚¸ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    rolled_edges = {yd: roll_yaw(scan_edge, yd, YAW_RES_DEG) for yd in yaw_candidates}

    best = dict(score=-1e9, x=None, y=None, yaw=None)
    for y0 in ys:
        for x0 in xs:
            ref_img = pc_to_image_for_viewpoint(map_pts, (x0, y0), z_view=0.0)
            ref_edge = to_edges(ref_img)
            for yd in yaw_candidates:
                s = ncc_on_valid(ref_edge, rolled_edges[yd], NCC_MIN_COMMON_PIX)
                if s > best["score"]:
                    best.update(score=s, x=x0, y=y0, yaw=yd)
    return best

def visualize_outputs_only_four(map_pts, scan_pts, best, outdir):
    """æŒ‡å®šã®4æšã ã‘ã‚’ä¿å­˜ã€‚"""
    # 1) å·¦å³æ¯”è¼ƒ / 2) ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ (ã‚¨ãƒƒã‚¸ã§ã¯ãªãæ·±åº¦ç”»åƒã®å¯è¦–åŒ–ã‚’ä½¿ç”¨)
    ref_img = pc_to_image_for_viewpoint(map_pts, (best["x"], best["y"]), z_view=0.0)
    scan_img = to_polar_image(scan_pts, YAW_RES_DEG, PITCH_RES_DEG,
                              PITCH_MIN_DEG, PITCH_MAX_DEG, DEPTH_SCALE)
    scan_rot = roll_yaw(scan_img, best["yaw"], YAW_RES_DEG)

    ref_norm  = cv2.normalize(ref_img,  None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    scan_norm = cv2.normalize(scan_rot, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    # (A) compare_side_by_side.png
    side = np.hstack([ref_norm, scan_norm])
    side_rgb = cv2.cvtColor(side, cv2.COLOR_GRAY2BGR)
    cv2.putText(side_rgb, "Map render (left)  |  LiDAR render (right)",
                (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)
    cv2.imwrite(os.path.join(outdir, "compare_side_by_side.png"), side_rgb)

    # (B) compare_overlay_color.png
    h, w = ref_norm.shape
    overlay = np.zeros((h, w, 3), np.uint8)
    overlay[..., 1] = ref_norm     # G: Map
    overlay[..., 2] = scan_norm    # R: Scan
    cv2.putText(overlay, "Overlay: Map=Green, LiDAR=Red (gray=match)",
                (20, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)
    cv2.imwrite(os.path.join(outdir, "compare_overlay_color.png"), overlay)

    # (C) estimated_pose_on_map.png
    plt.figure(figsize=(8, 8))
    plt.scatter(map_pts[:, 0], map_pts[:, 1], s=0.2, c='gray', alpha=0.5)
    plt.arrow(best["x"], best["y"],
              5 * math.cos(deg2rad(best["yaw"])),
              5 * math.sin(deg2rad(best["yaw"])),
              color='red', head_width=1.0, length_includes_head=True)
    plt.title(f"Estimated Pose on Map (score={best['score']:.3f})")
    plt.xlabel("X [m]"); plt.ylabel("Y [m]")
    plt.axis("equal")
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "estimated_pose_on_map.png"), dpi=300)
    plt.close()

    # (D) alignment_topdown.pngï¼ˆæ¨å®šå§¿å‹¢ã§ã‚¹ã‚­ãƒ£ãƒ³ã‚’XYã¸é‡ã­ï¼‰
    yaw = deg2rad(best["yaw"])
    Rz = np.array([[math.cos(yaw), -math.sin(yaw), 0],
                   [math.sin(yaw),  math.cos(yaw), 0],
                   [0, 0, 1]])
    scan_tf = (scan_pts @ Rz.T) + np.array([best["x"], best["y"], 0.0])
    plt.figure(figsize=(8, 8))
    plt.scatter(map_pts[:, 0], map_pts[:, 1], s=0.2, c='gray', alpha=0.5, label="Map")
    plt.scatter(scan_tf[:, 0], scan_tf[:, 1], s=0.5, c='red',  alpha=0.6, label="Scan")
    plt.axis("equal"); plt.xlabel("X [m]"); plt.ylabel("Y [m]")
    plt.title("Map vs Scan Alignment (Top-Down)")
    plt.tight_layout()
    plt.savefig(os.path.join(outdir, "alignment_topdown.png"), dpi=300)
    plt.close()

def main():
    ensure_dir(OUTPUT_DIR)

    # 1) åœ°å›³èª­ã¿è¾¼ã¿
    if not os.path.exists(MAP_PATH):
        raise FileNotFoundError(f"åœ°å›³ãŒã‚ã‚Šã¾ã›ã‚“: {MAP_PATH}")
    map_pcd = o3d.io.read_point_cloud(MAP_PATH)
    if MAP_RANDOM_DOWNSAMPLE < 1.0:
        map_pcd = map_pcd.random_down_sample(MAP_RANDOM_DOWNSAMPLE)
    map_pts = np.asarray(map_pcd.points)
    if map_pts.size == 0:
        raise ValueError("åœ°å›³ç‚¹ç¾¤ãŒç©ºã§ã™ã€‚PLYã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    # åœ°å›³Zè»¸åè»¢ï¼ˆè¦æ±‚é€šã‚Šç¶­æŒï¼‰
    map_pts[:, 2] *= -1

    # 2) ã‚¹ã‚­ãƒ£ãƒ³æŠ½å‡º
    scan_pts = extract_frame_points_from_pcap(PCAP_PATH, JSON_PATH, FRAME_INDEX)
    if scan_pts.size == 0:
        raise ValueError("ã‚¹ã‚­ãƒ£ãƒ³ç‚¹ç¾¤ãŒç©ºã§ã™ã€‚PCAP/JSONã¨FRAME_INDEXã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # 3) ã‚¹ã‚­ãƒ£ãƒ³ã‚’ç”»åƒåŒ– â†’ ã‚¨ãƒƒã‚¸åŒ–ï¼ˆå›ºå®šä¸€å›ï¼‰
    scan_img = to_polar_image(scan_pts, YAW_RES_DEG, PITCH_RES_DEG,
                              PITCH_MIN_DEG, PITCH_MAX_DEG, DEPTH_SCALE)
    scan_edge = to_edges(scan_img)

    # 4) æ¢ç´¢ä¸­å¿ƒï¼ˆè‡ªå‹•ï¼‰
    if AUTO_CENTER_BY_DENSITY:
        cx, cy = auto_center_by_density(map_pts, COARSE_BIN_M)
    else:
        cx, cy, _ = map_pts.mean(axis=0)

    # 5) ç²—æ¢ç´¢
    best = search_xy_yaw(map_pts, scan_edge, cx, cy,
                         SEARCH_XY_RADIUS_COARSE, SEARCH_XY_STEP_COARSE, YAW_STEP_DEG_COARSE)

    # 6) ç´°æ¢ç´¢ï¼ˆç²—ãƒ™ã‚¹ãƒˆè¿‘å‚ï¼‰
    best2 = search_xy_yaw(map_pts, scan_edge, best["x"], best["y"],
                          SEARCH_XY_RADIUS_FINE, SEARCH_XY_STEP_FINE, YAW_STEP_DEG_FINE)
    if best2["score"] > best["score"]:
        best = best2

    # 7) å¤±æ•—åˆ¤å®šã¨å¯è¦–åŒ–ï¼ˆ4æšã®ã¿ï¼‰
    if best["score"] < FAIL_SCORE_THRESHOLD:
        print(f"âŒ ãƒãƒƒãƒå¤±æ•—: score={best['score']:.3f} < {FAIL_SCORE_THRESHOLD}")
        # å¤±æ•—ã§ã‚‚æ¯”è¼ƒç”»åƒã¯æ¬²ã—ã„å ´åˆã¯ä»¥ä¸‹ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤
        # visualize_outputs_only_four(map_pts, scan_pts, best, OUTPUT_DIR)
        return

    visualize_outputs_only_four(map_pts, scan_pts, best, OUTPUT_DIR)
    print("âœ… å‡ºåŠ›:", ", ".join([
        "compare_side_by_side.png",
        "compare_overlay_color.png",
        "estimated_pose_on_map.png",
        "alignment_topdown.png"
    ]))
    print(f"ğŸ§­ æ¨å®š: x={best['x']:.2f}, y={best['y']:.2f}, yaw={best['yaw']:.1f}Â°, score={best['score']:.3f}")

if __name__ == "__main__":
    main()
